{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Learn OpenCode While Doing the Workshop\n",
    "\n",
    "## Practical guide with commands to run in your terminal\n",
    "\n",
    "**OpenCode** is a terminal-based coding assistant that lets you interact with LLMs (Claude, GPT, etc.) directly from the command line.\n",
    "\n",
    "---\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "1. **Keep this notebook open** as a reference\n",
    "2. **Open a terminal** on your computer\n",
    "3. **Copy and run** the commands shown\n",
    "4. **Switch back and forth** between this tutorial and the workshop notebooks\n",
    "\n",
    "Each section is synchronized with the main workshop notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installation and Setup\n",
    "\n",
    "### Install OpenCode\n",
    "\n",
    "```bash\n",
    "# Option 1: With npm (Node.js)\n",
    "npm install -g @anthropics/opencode\n",
    "\n",
    "# Option 2: With Homebrew (macOS)\n",
    "brew install opencode\n",
    "\n",
    "# Option 3: Direct download\n",
    "curl -fsSL https://opencode.ai/install.sh | sh\n",
    "```\n",
    "\n",
    "### Verify installation\n",
    "\n",
    "```bash\n",
    "opencode --version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Getting Started\n",
    "\n",
    "While learning API fundamentals in Notebook 1, try these basic OpenCode commands.\n",
    "\n",
    "### 1.1 Start OpenCode\n",
    "\n",
    "```bash\n",
    "# Navigate to the workshop directory\n",
    "cd ~/path/to/code-llm-allies-2026\n",
    "\n",
    "# Start OpenCode\n",
    "opencode\n",
    "```\n",
    "\n",
    "### 1.2 Your first prompt\n",
    "\n",
    "Once inside OpenCode, type:\n",
    "\n",
    "```\n",
    "Explain what an LLM API is in 3 simple sentences\n",
    "```\n",
    "\n",
    "### 1.3 Explore the project\n",
    "\n",
    "```\n",
    "What files are in this project? Give me a summary of the structure\n",
    "```\n",
    "\n",
    "### 1.4 Read a file\n",
    "\n",
    "```\n",
    "Read the file data/paper_abstracts.txt and tell me how many abstracts it contains\n",
    "```\n",
    "\n",
    "### 1.5 Analyze text (like in Notebook 1)\n",
    "\n",
    "```\n",
    "Read the first abstract from data/paper_abstracts.txt and:\n",
    "1. Summarize it in 2 sentences for someone without technical knowledge\n",
    "2. Extract the 3 most important keywords\n",
    "3. Suggest a more accessible alternative title\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Visualization \n",
    "\n",
    "While working with visualizations in Notebook 2, try generating plots with OpenCode.\n",
    "\n",
    "### 2.1 Explore data\n",
    "\n",
    "```\n",
    "Read data/climate_data.csv and tell me:\n",
    "- How many rows and columns it has\n",
    "- What data types are in each column\n",
    "- A basic statistical summary\n",
    "```\n",
    "\n",
    "### 2.2 Create a simple visualization\n",
    "\n",
    "```\n",
    "Create a Python script that:\n",
    "1. Loads data/climate_data.csv\n",
    "2. Makes a line plot of temperature vs date\n",
    "3. Saves the plot as temperature_plot.png\n",
    "4. Run the script\n",
    "```\n",
    "\n",
    "### 2.3 More complex visualization\n",
    "\n",
    "```\n",
    "Using data/climate_data.csv, create a visualization that shows:\n",
    "- Temperature on the Y axis\n",
    "- Date on the X axis\n",
    "- Different colors for each location\n",
    "- A trend line (6-month rolling average)\n",
    "- Clean publication-ready style\n",
    "\n",
    "Save it as climate_trends.png\n",
    "```\n",
    "\n",
    "### 2.4 Bar chart with error bars\n",
    "\n",
    "```\n",
    "With data/experiment_results.csv:\n",
    "1. Calculate the mean and standard deviation of 'measurement' by 'treatment'\n",
    "2. Create a bar chart with error bars\n",
    "3. Use colorblind-friendly colors\n",
    "4. Save as treatment_comparison.png\n",
    "```\n",
    "\n",
    "### 2.5 Refine iteratively\n",
    "\n",
    "After creating a plot, you can ask for modifications:\n",
    "\n",
    "```\n",
    "In the last plot you created:\n",
    "- Increase the font size to 14pt\n",
    "- Add a descriptive title\n",
    "- Change the background to white\n",
    "- Save the updated version\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Automation \n",
    "\n",
    "While learning to automate tasks in Notebook 3, use OpenCode for real tasks.\n",
    "\n",
    "### 3.1 Analyze problematic data\n",
    "\n",
    "```\n",
    "Read data/messy_data.csv and analyze:\n",
    "1. What data quality issues do you find?\n",
    "2. Which columns have inconsistent formats?\n",
    "3. How many missing values are there per column?\n",
    "```\n",
    "\n",
    "### 3.2 Create a cleaning function\n",
    "\n",
    "```\n",
    "Based on the problems you found in messy_data.csv,\n",
    "create a Python script called clean_data.py that:\n",
    "\n",
    "1. Defines a function clean_messy_data(filepath) that:\n",
    "   - Cleans the 'concentration' column (extract numbers only)\n",
    "   - Standardizes dates to YYYY-MM-DD format\n",
    "   - Cleans the 'temperature' column (extract numeric values)\n",
    "   - Converts 'cell_count' to standard numeric format\n",
    "   - Standardizes 'status' to Title Case\n",
    "\n",
    "2. Saves the result as messy_data_cleaned.csv\n",
    "3. Prints a summary of changes made\n",
    "\n",
    "Run the script and show me the result.\n",
    "```\n",
    "\n",
    "### 3.3 Process multiple files\n",
    "\n",
    "```\n",
    "Create a script that:\n",
    "1. Lists all CSV files in the data/ folder\n",
    "2. For each file, generates basic statistics\n",
    "3. Saves a summary to data_summary.txt\n",
    "```\n",
    "\n",
    "### 3.4 Generate automatic documentation\n",
    "\n",
    "```\n",
    "For the clean_data.py file we just created:\n",
    "1. Add comprehensive docstrings to all functions\n",
    "2. Add type hints\n",
    "3. Add usage examples in the docstrings\n",
    "```\n",
    "\n",
    "### 3.5 Create analysis pipeline\n",
    "\n",
    "```\n",
    "Create a script analysis_pipeline.py that:\n",
    "\n",
    "1. Loads experiment_results.csv\n",
    "2. Calculates descriptive statistics by treatment group\n",
    "3. Runs an ANOVA test to compare groups\n",
    "4. Generates a visualization of the results\n",
    "5. Saves a report in Markdown format with:\n",
    "   - Statistics table\n",
    "   - Statistical test result\n",
    "   - Interpretation of results\n",
    "\n",
    "Run the complete pipeline.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Complex Agent-like Tasks \n",
    "\n",
    "While learning about agents in Notebook 4, observe how OpenCode acts as an agent.\n",
    "\n",
    "### 4.1 Complete exploratory analysis\n",
    "\n",
    "```\n",
    "Perform a complete exploratory analysis of experiment_results.csv:\n",
    "\n",
    "1. Load and explore the data\n",
    "2. Identify the most important variables\n",
    "3. Look for significant correlations\n",
    "4. Compare treatment groups\n",
    "5. Create relevant visualizations\n",
    "6. Generate a report with your main findings\n",
    "\n",
    "Save everything in a folder called 'analysis_output'\n",
    "```\n",
    "\n",
    "### 4.2 Data investigation\n",
    "\n",
    "```\n",
    "Investigate whether there are significant differences in experiment \n",
    "results by species:\n",
    "\n",
    "1. Explore the data\n",
    "2. Decide which statistical tests are appropriate\n",
    "3. Run the analyses\n",
    "4. Create visualizations that illustrate your findings\n",
    "5. Write a conclusion in simple language\n",
    "```\n",
    "\n",
    "### 4.3 Scientific report generation\n",
    "\n",
    "```\n",
    "Based on the analysis of experiment_results.csv, generate:\n",
    "\n",
    "1. A Methods section for a scientific paper\n",
    "2. A Results section with:\n",
    "   - Description of findings\n",
    "   - References to figures\n",
    "   - Properly formatted statistical values\n",
    "3. Figure legends for the generated figures\n",
    "\n",
    "Save everything in a file called report.md\n",
    "```\n",
    "\n",
    "### 4.4 Multi-step task with decisions\n",
    "\n",
    "```\n",
    "I have survey data in survey_responses.csv.\n",
    "I want to understand what factors influence satisfaction (q1_satisfaction).\n",
    "\n",
    "Please:\n",
    "1. Explore the data and understand its structure\n",
    "2. Identify possible predictors of satisfaction\n",
    "3. Decide which analyses are appropriate (correlations, group comparisons, etc.)\n",
    "4. Run the analyses you consider relevant\n",
    "5. Create visualizations that tell the story\n",
    "6. Give me recommendations based on the data\n",
    "\n",
    "Document your decision process at each step.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Useful OpenCode Commands\n",
    "\n",
    "### Commands inside OpenCode\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    "| `/help` | Show help and available commands |\n",
    "| `/clear` | Clear the conversation context |\n",
    "| `/model` | Change the model (claude, gpt-4, etc.) |\n",
    "| `/compact` | Compact history to save tokens |\n",
    "| `/cost` | Show estimated session cost |\n",
    "| `/exit` or `Ctrl+C` | Exit OpenCode |\n",
    "\n",
    "### Keyboard shortcuts\n",
    "\n",
    "| Shortcut | Action |\n",
    "|----------|--------|\n",
    "| `Tab` | Autocomplete |\n",
    "| `Up/Down` | Navigate history |\n",
    "| `Ctrl+C` | Cancel current operation |\n",
    "| `Ctrl+L` | Clear screen |\n",
    "\n",
    "### Usage tips\n",
    "\n",
    "```\n",
    "# Check your session cost\n",
    "/cost\n",
    "\n",
    "# Switch to a more economical model\n",
    "/model gpt-4o-mini\n",
    "\n",
    "# Clear context if the conversation gets confusing\n",
    "/clear\n",
    "\n",
    "# Compact history for long sessions\n",
    "/compact\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Principles for Effective Use of Code Agents\n",
    "\n",
    "### 6.1 The Golden Rules\n",
    "\n",
    "| Principle | Why It Matters |\n",
    "|-----------|----------------|\n",
    "| **Be specific** | Vague requests lead to generic solutions |\n",
    "| **Provide context** | The agent doesn't know your project |\n",
    "| **Iterate, don't restart** | Build on previous responses |\n",
    "| **Verify outputs** | AI can make mistakes, especially with statistics |\n",
    "| **Break down complex tasks** | Smaller steps = better results |\n",
    "\n",
    "### 6.2 How to Write Effective Prompts\n",
    "\n",
    "#### Bad vs Good Prompts\n",
    "\n",
    "```\n",
    "# BAD: Too vague\n",
    "\"Analyze my data\"\n",
    "\n",
    "# GOOD: Specific and contextual\n",
    "\"Analyze experiment_results.csv: compare the 'measurement' column \n",
    "across the three treatment groups using ANOVA, create a box plot \n",
    "with significance annotations, and save results to analysis_output/\"\n",
    "```\n",
    "\n",
    "```\n",
    "# BAD: No context about your needs\n",
    "\"Make a plot\"\n",
    "\n",
    "# GOOD: Clear requirements\n",
    "\"Create a publication-ready figure for Nature journal:\n",
    "- Bar plot of mean ± SEM for each treatment\n",
    "- Individual data points overlaid\n",
    "- 300 DPI, Arial font, no gridlines\n",
    "- Significance bars with asterisks (* p<0.05, ** p<0.01)\"\n",
    "```\n",
    "\n",
    "```\n",
    "# BAD: Assuming the agent knows your data\n",
    "\"Calculate the IC50\"\n",
    "\n",
    "# GOOD: Providing necessary context\n",
    "\"In dose_response.csv, the 'concentration' column has drug doses in µM\n",
    "and 'viability' has cell viability as percentage. Fit a 4-parameter \n",
    "logistic curve and calculate IC50 with 95% confidence interval.\"\n",
    "```\n",
    "\n",
    "### 6.3 The CLEAR Framework for Scientific Prompts\n",
    "\n",
    "**C** - Context: What is your data? What field are you in?\n",
    "**L** - Language: Use precise scientific terminology\n",
    "**E** - Expected output: What format do you need?\n",
    "**A** - Assumptions: State any constraints or requirements\n",
    "**R** - Review criteria: How will you verify the result?\n",
    "\n",
    "```\n",
    "# Example using CLEAR framework:\n",
    "\n",
    "CONTEXT: I have qPCR data in 'qpcr_results.csv' with Ct values \n",
    "for a gene of interest and housekeeping gene across 3 conditions.\n",
    "\n",
    "LANGUAGE: I need to calculate delta-delta Ct (2^-ΔΔCt method) \n",
    "for relative gene expression.\n",
    "\n",
    "EXPECTED OUTPUT: \n",
    "- Bar plot with fold change vs control\n",
    "- Error bars showing SEM from 3 biological replicates\n",
    "- Statistical comparison using one-way ANOVA\n",
    "\n",
    "ASSUMPTIONS:\n",
    "- Control condition is \"untreated\"\n",
    "- Housekeeping gene is \"GAPDH\"\n",
    "- Alpha level is 0.05\n",
    "\n",
    "REVIEW: I will verify by manually calculating one sample.\n",
    "```\n",
    "\n",
    "### 6.4 When to Trust (and Not Trust) the Agent\n",
    "\n",
    "#### Generally Safe to Trust:\n",
    "- File operations (reading, writing, organizing)\n",
    "- Basic visualizations (plots, charts)\n",
    "- Code syntax and structure\n",
    "- Data transformations (filtering, merging, reshaping)\n",
    "- Formatting and documentation\n",
    "\n",
    "#### Always Verify:\n",
    "- Statistical test selection and interpretation\n",
    "- Mathematical calculations (especially p-values)\n",
    "- Biological/scientific interpretations\n",
    "- Sample size recommendations\n",
    "- Conclusions and claims about significance\n",
    "\n",
    "#### How to Verify:\n",
    "```\n",
    "# After statistical analysis, ask:\n",
    "\"Show me the intermediate calculations for the ANOVA:\n",
    "- Group means and variances\n",
    "- Degrees of freedom\n",
    "- F-statistic calculation\n",
    "- How was the p-value derived?\"\n",
    "\n",
    "# For complex analyses:\n",
    "\"Run the same analysis using a different method/package \n",
    "and compare results\"\n",
    "```\n",
    "\n",
    "### 6.5 Iterative Refinement Strategy\n",
    "\n",
    "#### The 3-Step Approach:\n",
    "\n",
    "```\n",
    "# STEP 1: Start broad, get something working\n",
    "\"Create a basic analysis of experiment_results.csv\"\n",
    "\n",
    "# STEP 2: Refine specific aspects\n",
    "\"Now improve the visualization:\n",
    "- Change to colorblind-friendly palette\n",
    "- Add proper axis labels with units\n",
    "- Increase font size to 12pt\"\n",
    "\n",
    "# STEP 3: Polish for final output\n",
    "\"Make this publication-ready:\n",
    "- Export as 300 DPI TIFF\n",
    "- Add figure panel labels (A, B, C)\n",
    "- Ensure it fits in a single column (8.5 cm width)\"\n",
    "```\n",
    "\n",
    "#### When to Start Fresh vs. Continue:\n",
    "\n",
    "| Continue the conversation | Start fresh (/clear) |\n",
    "|--------------------------|---------------------|\n",
    "| Refining the same analysis | Completely different task |\n",
    "| Fixing errors in recent code | Agent seems confused |\n",
    "| Adding features to existing script | Too much irrelevant context |\n",
    "| Iterating on visualizations | Starting a new dataset |\n",
    "\n",
    "### 6.6 Handling Errors Effectively\n",
    "\n",
    "```\n",
    "# When code fails, provide:\n",
    "1. The exact error message\n",
    "2. What you were trying to do\n",
    "3. Any relevant context\n",
    "\n",
    "# Example:\n",
    "\"The previous code failed with:\n",
    "ValueError: could not convert string to float: '1.5 mM'\n",
    "\n",
    "I'm trying to analyze the concentration column which has mixed \n",
    "formats (some numeric, some with units). Please fix the code \n",
    "to handle unit extraction.\"\n",
    "```\n",
    "\n",
    "### 6.7 Scientific Integrity Guidelines\n",
    "\n",
    "#### DO:\n",
    "- Verify statistical outputs manually for key results\n",
    "- Keep a record of prompts used (for reproducibility)\n",
    "- State in methods if AI tools were used for analysis\n",
    "- Double-check biological interpretations\n",
    "\n",
    "#### DON'T:\n",
    "- Blindly trust p-values or statistical conclusions\n",
    "- Let the agent choose statistical tests without understanding why\n",
    "- Use AI-generated interpretations directly in papers\n",
    "- Assume the agent understands your specific experimental design\n",
    "\n",
    "```\n",
    "# Good practice: Ask for explanations\n",
    "\"You chose a Mann-Whitney U test. Explain why this is more \n",
    "appropriate than a t-test for my data, and what assumptions \n",
    "are we checking/violating.\"\n",
    "```\n",
    "\n",
    "### 6.8 Prompt Templates for Common Scientific Tasks\n",
    "\n",
    "#### Statistical Analysis\n",
    "```\n",
    "Analyze [file] to test if [variable] differs between [groups].\n",
    "- Check assumptions for parametric tests\n",
    "- Choose appropriate test and justify\n",
    "- Report: test statistic, degrees of freedom, p-value, effect size\n",
    "- Create visualization with significance annotations\n",
    "- Write a results sentence in scientific format\n",
    "```\n",
    "\n",
    "#### Figure Generation\n",
    "```\n",
    "Create a publication figure from [file]:\n",
    "- Plot type: [bar/scatter/line/box/violin]\n",
    "- X-axis: [column] (label: \"[Label with units]\")\n",
    "- Y-axis: [column] (label: \"[Label with units]\")\n",
    "- Grouping: [column for colors/panels]\n",
    "- Style: [journal name] guidelines\n",
    "- Export: [format], [DPI], [dimensions]\n",
    "```\n",
    "\n",
    "#### Data Cleaning\n",
    "```\n",
    "Clean [file] for analysis:\n",
    "- Expected columns: [list]\n",
    "- [column1] should be: [type, range, format]\n",
    "- [column2] should be: [type, range, format]\n",
    "- Handle missing values by: [strategy]\n",
    "- Flag but don't remove outliers beyond [X] SD\n",
    "- Export cleaned data and QC report\n",
    "```\n",
    "\n",
    "#### Literature Analysis\n",
    "```\n",
    "Read [abstracts file] and for each paper extract:\n",
    "- Main finding (1 sentence)\n",
    "- Methodology used\n",
    "- Sample size/model organism\n",
    "- Key statistics reported\n",
    "- Limitations mentioned\n",
    "Create a summary table in markdown format.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Progressive Exercises\n",
    "\n",
    "### Beginner Level\n",
    "\n",
    "```\n",
    "# Exercise 1: Basic data exploration\n",
    "Read data/experiment_results.csv and tell me:\n",
    "- How many subjects per treatment group?\n",
    "- What is the mean measurement for each treatment?\n",
    "- Are there any missing values?\n",
    "\n",
    "# Exercise 2: Quick statistics\n",
    "Calculate the mean, median, and standard deviation of 'growth_rate' \n",
    "in experiment_results.csv, grouped by 'species'\n",
    "\n",
    "# Exercise 3: Simple visualization\n",
    "Create a box plot comparing 'measurement' across treatment groups\n",
    "from experiment_results.csv. Save it as treatment_boxplot.png\n",
    "\n",
    "# Exercise 4: Data summary\n",
    "Read all CSV files in the data/ folder and create a summary table\n",
    "showing: filename, number of rows, number of columns, column names\n",
    "\n",
    "# Exercise 5: Literature helper\n",
    "Read data/paper_abstracts.txt and for each abstract:\n",
    "- Identify the main methodology used\n",
    "- List the key findings\n",
    "- Suggest 3 related search terms for PubMed\n",
    "```\n",
    "\n",
    "### Intermediate Level\n",
    "\n",
    "```\n",
    "# Exercise 6: Statistical comparison\n",
    "Using experiment_results.csv:\n",
    "- Run an ANOVA to compare measurements across treatments\n",
    "- If significant, run post-hoc Tukey tests\n",
    "- Create a visualization showing significant differences with asterisks\n",
    "- Save results to statistical_analysis.txt\n",
    "\n",
    "# Exercise 7: Publication-ready figure\n",
    "Create a multi-panel figure (2x2) from experiment_results.csv showing:\n",
    "- Panel A: Bar plot of mean measurement by treatment (with SEM error bars)\n",
    "- Panel B: Scatter plot of measurement vs growth_rate colored by species\n",
    "- Panel C: Distribution of measurements (histogram + KDE)\n",
    "- Panel D: Box plot by treatment and species\n",
    "Use publication style (Nature/Science guidelines): 300 DPI, proper fonts\n",
    "\n",
    "# Exercise 8: Data cleaning pipeline\n",
    "Create a script clean_lab_data.py that:\n",
    "- Reads messy_data.csv\n",
    "- Standardizes all date formats to ISO format\n",
    "- Converts concentration values to numeric (handling 'mM', 'uM' units)\n",
    "- Flags outliers using IQR method\n",
    "- Exports clean data and a QC report\n",
    "\n",
    "# Exercise 9: Batch figure generation\n",
    "Create a script that reads experiment_results.csv and automatically generates:\n",
    "- One figure per unique value in 'species' column\n",
    "- Each figure shows measurement vs treatment for that species\n",
    "- Saves all figures in a 'figures/' folder with descriptive names\n",
    "\n",
    "# Exercise 10: Methods section generator\n",
    "Based on the analysis of experiment_results.csv, generate a Methods section\n",
    "that includes:\n",
    "- Sample sizes per group\n",
    "- Statistical tests used (with software/version)\n",
    "- Significance threshold\n",
    "- How data was visualized\n",
    "Format it for a scientific journal submission.\n",
    "\n",
    "# Exercise 11: Supplementary table creator\n",
    "Create a script that generates formatted supplementary tables:\n",
    "- Table S1: Descriptive statistics by group\n",
    "- Table S2: Full statistical test results\n",
    "- Table S3: Individual subject data\n",
    "Export as both CSV and formatted Excel with proper headers\n",
    "```\n",
    "\n",
    "### Advanced Level\n",
    "\n",
    "```\n",
    "# Exercise 12: Reproducible analysis notebook\n",
    "Convert a complete analysis of experiment_results.csv into a \n",
    "Jupyter notebook suitable for journal submission:\n",
    "- Introduction cell explaining the analysis\n",
    "- Data loading with validation checks\n",
    "- Exploratory data analysis with figures\n",
    "- Statistical tests with interpretation\n",
    "- Publication-ready figures with captions\n",
    "- Conclusions and limitations\n",
    "- Session info (package versions)\n",
    "\n",
    "# Exercise 13: Power analysis tool\n",
    "Create a script power_analysis.py that:\n",
    "- Takes pilot data (experiment_results.csv)\n",
    "- Calculates effect sizes between groups\n",
    "- Estimates required sample size for 80% power\n",
    "- Creates a power curve visualization\n",
    "- Outputs recommendations for future experiments\n",
    "\n",
    "# Exercise 14: Meta-analysis helper\n",
    "Create a tool that:\n",
    "- Reads multiple experiment CSV files\n",
    "- Extracts effect sizes and confidence intervals\n",
    "- Creates a forest plot\n",
    "- Calculates pooled effect size\n",
    "- Tests for heterogeneity\n",
    "```\n",
    "\n",
    "### Lab Productivity Tools\n",
    "\n",
    "```\n",
    "# Exercise 15: Experiment tracker dashboard\n",
    "Create a Streamlit app for tracking lab experiments:\n",
    "- Upload CSV files with experiment results\n",
    "- Automatic QC checks (missing data, outliers, expected ranges)\n",
    "- Quick visualization of results\n",
    "- Compare with previous experiments\n",
    "- Export summary for lab notebook\n",
    "- Track experiments by date, project, researcher\n",
    "\n",
    "Save as lab_dashboard.py and run with: streamlit run lab_dashboard.py\n",
    "\n",
    "# Exercise 16: Protocol optimizer\n",
    "Build a tool that analyzes experiment_results.csv to:\n",
    "- Identify which conditions give best results\n",
    "- Suggest optimal parameter combinations\n",
    "- Show dose-response curves if applicable\n",
    "- Calculate EC50/IC50 values\n",
    "- Generate protocol recommendations\n",
    "\n",
    "# Exercise 17: Lab meeting figure generator\n",
    "Create an app that quickly generates presentation-ready figures:\n",
    "- Input: CSV data file\n",
    "- Select variables to plot\n",
    "- Choose plot type (bar, scatter, line, box, violin)\n",
    "- Auto-apply consistent lab style (colors, fonts)\n",
    "- Add statistical annotations automatically\n",
    "- Export as PNG and PowerPoint-compatible format\n",
    "\n",
    "# Exercise 18: Grant figure assistant\n",
    "Build a Streamlit app that helps create figures for grant applications:\n",
    "- Loads preliminary data from CSV\n",
    "- Generates publication-quality figures\n",
    "- Adds projected data points for proposed experiments\n",
    "- Creates comparison with published literature (simulated)\n",
    "- Exports figures with proper legends for grant documents\n",
    "```\n",
    "\n",
    "### Research Workflow Automation\n",
    "\n",
    "```\n",
    "# Exercise 19: Plate reader analysis pipeline\n",
    "Create a complete analysis pipeline for 96-well plate data:\n",
    "- Read raw plate reader CSV output\n",
    "- Apply blank subtraction\n",
    "- Calculate means and standard deviations for replicates\n",
    "- Normalize to control wells\n",
    "- Fit dose-response curves\n",
    "- Generate heatmap of plate layout\n",
    "- Export results and QC report\n",
    "\n",
    "# Exercise 20: Microscopy image quantification report\n",
    "Build a tool that processes microscopy quantification data:\n",
    "- Read CSV with cell counts, intensities, areas\n",
    "- Calculate statistics per condition/treatment\n",
    "- Generate violin plots for distributions\n",
    "- Perform statistical comparisons\n",
    "- Create a PDF report with all figures and stats\n",
    "- Include methods description for paper\n",
    "\n",
    "# Exercise 21: Time-course analysis\n",
    "Create an analysis pipeline for time-series experiment data:\n",
    "- Read climate_data.csv (as example time-series)\n",
    "- Calculate rolling averages and trends\n",
    "- Detect change points\n",
    "- Fit growth/decay curves\n",
    "- Compare conditions over time\n",
    "- Generate figure with confidence intervals\n",
    "\n",
    "# Exercise 22: Multi-experiment meta-analyzer\n",
    "Build an application that:\n",
    "- Loads multiple experiment result files\n",
    "- Standardizes column names across files\n",
    "- Combines data with experiment identifier\n",
    "- Runs mixed-effects analysis\n",
    "- Creates publication-ready comparison figures\n",
    "- Generates combined statistics table\n",
    "```\n",
    "\n",
    "### Writing & Documentation Helpers\n",
    "\n",
    "```\n",
    "# Exercise 23: Results paragraph generator\n",
    "Create a tool that:\n",
    "- Reads statistical analysis output\n",
    "- Generates a results paragraph in scientific writing style\n",
    "- Includes proper statistical notation (F(2,45)=3.2, p=0.04)\n",
    "- Suggests figure references\n",
    "- Outputs in multiple formats (Word-ready, LaTeX)\n",
    "\n",
    "# Exercise 24: Figure legend writer\n",
    "Build a script that:\n",
    "- Takes a figure file and its source data\n",
    "- Analyzes what the figure shows\n",
    "- Generates a complete figure legend including:\n",
    "  - Brief description of what is shown\n",
    "  - Explanation of error bars/statistics\n",
    "  - Sample sizes\n",
    "  - Statistical test results\n",
    "  - Abbreviations\n",
    "\n",
    "# Exercise 25: Scientific presentation builder\n",
    "Create an app that generates presentation slides:\n",
    "- Input: experiment data CSV + key message\n",
    "- Output: \n",
    "  - Title slide with key finding\n",
    "  - Methods summary slide\n",
    "  - Results slides with auto-generated figures\n",
    "  - Conclusions slide\n",
    "  - Export as HTML or PDF slides\n",
    "```\n",
    "\n",
    "### Data Management & QC\n",
    "\n",
    "```\n",
    "# Exercise 26: Lab data validator\n",
    "Create a validation system for incoming data:\n",
    "- Define expected schema (columns, types, ranges)\n",
    "- Validate new CSV files against schema\n",
    "- Flag anomalies and potential errors\n",
    "- Generate QC report with pass/fail status\n",
    "- Suggest corrections for common issues\n",
    "\n",
    "# Exercise 27: Experiment reproducibility checker\n",
    "Build a tool that:\n",
    "- Compares results from replicate experiments\n",
    "- Calculates coefficient of variation\n",
    "- Identifies outlier experiments\n",
    "- Generates reproducibility report\n",
    "- Flags experiments that need to be repeated\n",
    "\n",
    "# Exercise 28: Data archival assistant\n",
    "Create a system for organizing completed experiments:\n",
    "- Read experiment data and metadata\n",
    "- Generate standardized folder structure\n",
    "- Create README with experiment summary\n",
    "- Archive raw data with checksums\n",
    "- Generate data availability statement for paper\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Troubleshooting Common Issues\n",
    "\n",
    "### \"File not found\"\n",
    "\n",
    "```\n",
    "# Check your current directory\n",
    "What directory are we in? List the available files.\n",
    "\n",
    "# Or specify the full path\n",
    "Read /full/path/to/file.csv\n",
    "```\n",
    "\n",
    "### \"Generated code has errors\"\n",
    "\n",
    "```\n",
    "The previous code failed with this error: [paste error]\n",
    "Please fix it and run again.\n",
    "```\n",
    "\n",
    "### \"Need more context\"\n",
    "\n",
    "```\n",
    "Before continuing, read these files to understand the context:\n",
    "- [file1]\n",
    "- [file2]\n",
    "Then [your request]\n",
    "```\n",
    "\n",
    "### \"Response is too long/short\"\n",
    "\n",
    "```\n",
    "# For more concise responses\n",
    "Answer in maximum 3 sentences: [question]\n",
    "\n",
    "# For more detailed responses\n",
    "Explain in detail, step by step: [question]\n",
    "```\n",
    "\n",
    "### \"Want to undo changes\"\n",
    "\n",
    "```\n",
    "Undo the last changes you made to file [name]\n",
    "\n",
    "# Or if using git\n",
    "Run git checkout [file] to restore the previous version\n",
    "```\n",
    "\n",
    "### \"Statistical results seem wrong\"\n",
    "\n",
    "```\n",
    "# Ask for verification\n",
    "\"Please verify the ANOVA results by:\n",
    "1. Showing me the group means and sample sizes\n",
    "2. Calculating the F-statistic step by step\n",
    "3. Comparing with an alternative method (e.g., scipy vs statsmodels)\"\n",
    "```\n",
    "\n",
    "### \"Agent is stuck in a loop\"\n",
    "\n",
    "```\n",
    "# Clear context and restart with a simpler request\n",
    "/clear\n",
    "\n",
    "# Then break down the task\n",
    "\"Let's start fresh. First, just read the file and show me the columns.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Cheat Sheet - Quick Reference\n",
    "\n",
    "### Common Scientific Tasks\n",
    "\n",
    "| Task | Prompt Template |\n",
    "|------|-----------------|\n",
    "| Explore data | `Read [file] and summarize: columns, types, missing values, basic stats` |\n",
    "| Compare groups | `Compare [variable] between [groups] in [file] using appropriate statistical test` |\n",
    "| Publication figure | `Create a [journal]-style figure: [plot type] of [variables], 300 DPI, proper labels` |\n",
    "| Clean messy data | `Clean [file]: standardize [column] format, handle missing values, flag outliers` |\n",
    "| Generate methods | `Write a Methods section based on the analysis of [file]` |\n",
    "| Power analysis | `Calculate required sample size for 80% power based on effect size in [file]` |\n",
    "| Batch process | `For each file in [folder], [action], save results to [output]` |\n",
    "\n",
    "### Statistical Analysis Prompts\n",
    "\n",
    "| Analysis | Prompt |\n",
    "|----------|--------|\n",
    "| t-test | `Compare [var] between [group1] and [group2], check normality first` |\n",
    "| ANOVA | `Run one-way ANOVA on [var] by [group], include post-hoc if significant` |\n",
    "| Correlation | `Calculate Pearson/Spearman correlation between [var1] and [var2]` |\n",
    "| Regression | `Fit linear regression: [y] ~ [x1] + [x2], report coefficients and R²` |\n",
    "| Non-parametric | `Data is not normal. Use Mann-Whitney/Kruskal-Wallis for [comparison]` |\n",
    "\n",
    "### Figure Style Modifiers\n",
    "\n",
    "| Style | Add to prompt |\n",
    "|-------|---------------|\n",
    "| Nature/Science | `...following Nature guidelines: 8.5cm width, Arial, 300 DPI` |\n",
    "| Colorblind-safe | `...use colorblind-friendly palette (viridis or Color Universal Design)` |\n",
    "| Presentation | `...large fonts (18pt+), high contrast, simple design` |\n",
    "| Multi-panel | `...as 2x2 subplot with panels labeled A, B, C, D` |\n",
    "| With statistics | `...add significance annotations (* p<0.05, ** p<0.01, *** p<0.001)` |\n",
    "\n",
    "### Useful Modifiers\n",
    "\n",
    "| Add to prompt | Effect |\n",
    "|---------------|--------|\n",
    "| `...step by step` | Shows reasoning and intermediate results |\n",
    "| `...and run it` | Executes the generated code |\n",
    "| `...save as [name]` | Saves output to specified file |\n",
    "| `...explain the choice` | Justifies why a method/test was selected |\n",
    "| `...verify the results` | Double-checks calculations |\n",
    "| `...for journal submission` | Publication-ready formatting |\n",
    "| `...include effect size` | Reports Cohen's d, η², etc. |\n",
    "\n",
    "### The CLEAR Framework Reminder\n",
    "\n",
    "When writing prompts, include:\n",
    "- **C**ontext: What data? What field?\n",
    "- **L**anguage: Scientific terminology\n",
    "- **E**xpected output: Format needed\n",
    "- **A**ssumptions: Constraints, parameters\n",
    "- **R**eview: How to verify results\n",
    "\n",
    "---\n",
    "\n",
    "## Now practice!\n",
    "\n",
    "Open your terminal, start OpenCode, and begin with the exercise that corresponds to the notebook you're working on.\n",
    "\n",
    "Remember: \n",
    "- Start simple, then iterate\n",
    "- Always verify statistical results\n",
    "- Keep a log of your prompts for reproducibility\n",
    "- The best way to learn is by experimenting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
